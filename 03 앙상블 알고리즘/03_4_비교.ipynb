{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C73yItQyZXYD"
      },
      "outputs": [],
      "source": [
        "# prompt: 코랩에서 한글을 출력할 수 있게 해주세요\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import os, re\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "qqXCudtVZmsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://hycms.hanyang.ac.kr/index.php?module=xn_media_content2013&act=dispXn_media_content2013DownloadContent&content_id=66ef786538650\" -O \"data.zip\"\n",
        "!unzip  -O cp949 \"data.zip\" -d \"data\""
      ],
      "metadata": {
        "id": "xOMfw1SwZped"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %%\n",
        "\"\"\"학습용 데이터셋을 불러옴\"\"\"\n",
        "\n",
        "sdot_data_total = pd.read_csv('data/sdot학습데이터.csv', sep='|', encoding='cp949')\n",
        "sdot_data_total = sdot_data_total[~sdot_data_total['공'].isnull()]\n",
        "\"\"\"전체 Sdot 평균기온과의 온도차 평균이 높으면 1, 낮으면 -1으로 종속변수 생성\"\"\"\n",
        "sdot_data_total['종속'] = sdot_data_total['온도차이'].apply(lambda x: -1 if x < 0 else 1)\n",
        "\n",
        "\"\"\" 모든 입력변수를 이용한 분석\"\"\"\n",
        "tmp = sdot_data_total\n",
        "\n",
        "x = np.array(tmp[tmp.columns.drop(['종속', '시리얼번호', '온도차이', '온도비율차이'])].fillna(0).astype('float').values)\n",
        "y = np.array(tmp['종속'].values)\n",
        "y = y.reshape(y.shape[0], 1)"
      ],
      "metadata": {
        "id": "8GkBDr4nZyHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 학습 및 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-0bDEQzmaj4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: decision tree 분석\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 의사결정 트리 모델 생성 및 학습\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "aLvLvgfEad93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: bagging tree 분석\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# BaggingClassifier 모델 생성 및 학습\n",
        "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "print(\"Bagging Accuracy:\", accuracy_bagging)\n"
      ],
      "metadata": {
        "id": "PJX36AYgaxPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: random forest 분석\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤 포레스트 모델 생성 및 학습\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Accuracy:\", accuracy_rf)\n"
      ],
      "metadata": {
        "id": "cXt0vBt4a40B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: adaboost dtree 분석\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# AdaBoost 모델 생성 및 학습\n",
        "ada_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_ada = ada_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "print(\"AdaBoost Accuracy:\", accuracy_ada)\n"
      ],
      "metadata": {
        "id": "zvUra-LJa94q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gbm 분석\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# GBM 모델 생성 및 학습\n",
        "gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_gbm = gbm_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_gbm = accuracy_score(y_test, y_pred_gbm)\n",
        "print(\"GBM Accuracy:\", accuracy_gbm)\n"
      ],
      "metadata": {
        "id": "3OPUPbVEbH6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: xgboost 분석\n",
        "\n",
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# XGBoost 모델 생성 및 학습\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "y_train_xg = y_train.copy()\n",
        "y_train_xg[np.where(y_train_xg == -1)] = 0\n",
        "xgb_model.fit(X_train, y_train_xg)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"XGBoost Accuracy:\", accuracy_xgb)\n"
      ],
      "metadata": {
        "id": "sMJYwwuDbMH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: light GBM 분석\n",
        "\n",
        "!pip install lightgbm\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# LightGBM 모델 생성 및 학습\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
        "y_train_lgb = y_train.copy()\n",
        "y_train_lgb[np.where(y_train_lgb == -1)] = 0\n",
        "lgb_model.fit(X_train, y_train_lgb)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "print(\"LightGBM Accuracy:\", accuracy_lgb)\n"
      ],
      "metadata": {
        "id": "aWIh8FkhbgZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: catboost 분석\n",
        "\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# CatBoost 모델 생성 및 학습\n",
        "cat_model = CatBoostClassifier(iterations=100, random_state=42, verbose=0)\n",
        "y_train_cat = y_train.copy()\n",
        "y_train_cat[np.where(y_train_cat == -1)] = 0\n",
        "cat_model.fit(X_train, y_train_cat)\n",
        "\n",
        "# 테스트 세트로 예측 수행\n",
        "y_pred_cat = cat_model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
        "print(\"CatBoost Accuracy:\", accuracy_cat)\n"
      ],
      "metadata": {
        "id": "Fln4yIVvbqQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# prompt: 트레이닝과 테스트 셋에 대해서 위 모델들의 성능 지표(accuracy_score, precision_score, recall_score, f1_score)를 모두 측정하고 표로 표시\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "models = {\n",
        "    'Decision Tree': model,\n",
        "    'Bagging': bagging_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'AdaBoost': ada_model,\n",
        "    'GBM': gbm_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'CatBoost': cat_model\n",
        "}\n",
        "\n",
        "results = []\n",
        "for model_name, model in models.items():\n",
        "  if model_name == 'XGBoost' or model_name == 'LightGBM' or model_name == 'CatBoost':\n",
        "    y_train_mod = y_train.copy()\n",
        "    y_train_mod[np.where(y_train_mod == -1)] = 0\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    accuracy_train = accuracy_score(y_train_mod, y_pred_train)\n",
        "    precision_train = precision_score(y_train_mod, y_pred_train, average='macro') # Added average='macro'\n",
        "    recall_train = recall_score(y_train_mod, y_pred_train, average='macro') # Added average='macro'\n",
        "    f1_train = f1_score(y_train_mod, y_pred_train, average='macro') # Added average='macro'\n",
        "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "    precision_test = precision_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "    recall_test = recall_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "    f1_test = f1_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "  else:\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "    precision_train = precision_score(y_train, y_pred_train, average='macro') # Added average='macro'\n",
        "    recall_train = recall_score(y_train, y_pred_train, average='macro') # Added average='macro'\n",
        "    f1_train = f1_score(y_train, y_pred_train, average='macro') # Added average='macro'\n",
        "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "    precision_test = precision_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "    recall_test = recall_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "    f1_test = f1_score(y_test, y_pred_test, average='macro') # Added average='macro'\n",
        "\n",
        "  results.append([model_name, accuracy_train, precision_train, recall_train, f1_train, accuracy_test, precision_test, recall_test, f1_test])\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=['Model', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
        "df_results"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iZ6H6NnDcbeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: df_results의 정확도를 train과 test를 서로 다른 색깔로 차트로 표시해줘\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 모델 이름과 정확도를 추출\n",
        "models = df_results['Model']\n",
        "train_accuracy = df_results['Train Accuracy']\n",
        "test_accuracy = df_results['Test Accuracy']\n",
        "\n",
        "# 막대 그래프 생성\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_width = 0.35\n",
        "index = range(len(models))\n",
        "\n",
        "plt.bar(index, train_accuracy, width=bar_width, label='Train Accuracy', color='blue')\n",
        "plt.bar([i + bar_width for i in index], test_accuracy, width=bar_width, label='Test Accuracy', color='orange')\n",
        "\n",
        "# 축 레이블 및 제목 설정\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train vs. Test Accuracy for Different Models')\n",
        "\n",
        "# 막대 그래프에 모델 이름 표시\n",
        "plt.xticks([i + bar_width / 2 for i in index], models, rotation=45, ha='right')\n",
        "\n",
        "# 범례 표시\n",
        "plt.legend()\n",
        "\n",
        "# 그래프 출력\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mpoykv3UcsxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}